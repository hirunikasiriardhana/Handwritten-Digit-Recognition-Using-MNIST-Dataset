{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#01. Load and Preprocess the MNIST Dataset"
      ],
      "metadata": {
        "id": "_b0dtDEMTxwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GqyzfTN2TT2S"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "#tensorflow is the main library used for building and training the neural network\n",
        "import tensorflow as tf\n",
        "#mnist is a submodule of Keras (within TensorFlow) that contains the MNIST dataset.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "#Sequential is a Keras model type that allows you to build a neural network layer by layer.\n",
        "from tensorflow.keras.models import Sequential\n",
        "#Dense and Flatten are layers used in the neural network.\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "#to_categorical is a utility function that converts class vectors (integers) to binary class matrices (one-hot encoding).\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#matplotlib.pyplot is a plotting library used for visualizing the data and results.\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "#train_images and train_labels contain the training images and their corresponding labels.\n",
        "#test_images and test_labels contain the test images and their corresponding labels.\n",
        "#This line loads the MNIST dataset using the mnist.load_data() function from Keras.\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "imLQCmJXTVht"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images\n",
        "#The pixel values in the images range from 0 to 255.\n",
        "train_images = train_images / 255.0\n",
        "#Dividing by 255.0 normalizes these values to the range 0 to 1, which helps improve the performance and training speed of the neural network.\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "ssqzxuL6TVVp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "#The labels are originally integers (0-9). One-hot encoding converts these integers into binary matrices.\n",
        "#to_categorical is a Keras utility function that performs this conversion.\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "qu-53gtmTVKE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#02. Create a Neural Network Model"
      ],
      "metadata": {
        "id": "T4pmzqbHTrF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "#Sequential creates a linear stack of layers.\n",
        "model = Sequential([\n",
        "    #Flatten(input_shape=(28, 28)) converts the 28x28 2D images into a 1D array of 784 elements.\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    #Dense(128, activation='relu') adds a fully connected (dense) layer with 128 units and ReLU activation function.\n",
        "    #ReLU (Rectified Linear Unit) introduces non-linearity to the model.\n",
        "    Dense(128, activation='relu'),\n",
        "    #Dense(10, activation='softmax') adds a fully connected (dense) layer with 10 units (one for each digit) and softmax activation function,\n",
        "    #which outputs a probability distribution over the 10 classes.\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "zHuCLyxdT1sC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "#optimizer='adam' specifies the Adam optimizer, which is a popular optimization algorithm for training neural networks.\n",
        "model.compile(optimizer='adam',\n",
        "#loss='categorical_crossentropy' specifies the loss function for multi-class classification problems.\n",
        "              loss='categorical_crossentropy',\n",
        "#metrics=['accuracy'] specifies that we want to track accuracy during training and evaluation.\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wy_MtmRkT1jy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#03. Train the Model"
      ],
      "metadata": {
        "id": "C9wqAbvIT92L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "#model.fit trains the model on the training data.\n",
        "#epochs=10 specifies that the training process will run for 10 iterations over the entire dataset.\n",
        "#validation_split=0.2 specifies that 20% of the training data will be used for validation,\n",
        "#helping us monitor the model's performance on unseen data during training.\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guba-XrsT1Tw",
        "outputId": "8ba1c180-9a0f-43b0-8ea2-3594b4b620cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2907 - accuracy: 0.9180 - val_loss: 0.1565 - val_accuracy: 0.9558\n",
            "Epoch 2/10\n",
            "1183/1500 [======================>.......] - ETA: 0s - loss: 0.1316 - accuracy: 0.9611"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#04. Evaluate the Model"
      ],
      "metadata": {
        "id": "wiS7QZKYUGos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "#test_loss is the loss on the test data.test_acc is the accuracy on the test data.\n",
        "#model.evaluate computes the loss and accuracy of the model on the test data.\n",
        "#print outputs the test accuracy.\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "M7LDyU7nUDd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#05. Visualize the Results"
      ],
      "metadata": {
        "id": "2CiejIo2UOLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "#model.predict generates predictions for the test images.\n",
        "#predictions will contain the predicted probability distributions for each test image.\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "M7MogPUMUVqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 5 test images, their predicted labels, and the true labels\n",
        "# Color correct predictions in green and incorrect predictions in red\n",
        "#A loop iterates over the first 5 test images.\n",
        "for i in range(5):\n",
        "  #plt.figure(figsize=(6, 3)) creates a new figure with the specified size.\n",
        "    plt.figure(figsize=(6, 3))\n",
        "  #plt.subplot(1, 2, 1) creates a subplot for the image.\n",
        "    plt.subplot(1, 2, 1)\n",
        "  #plt.imshow(test_images[i], cmap=plt.cm.binary) displays the test image using a binary colormap.\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
        "  #plt.xlabel(f\"True: {test_labels[i].argmax()}\") labels the subplot with the true label.\n",
        "    plt.xlabel(f\"True: {test_labels[i].argmax()}\")\n",
        "  #plt.subplot(1, 2, 2) creates a subplot for the bar plot of predicted probabilities.\n",
        "    plt.subplot(1, 2, 2)\n",
        "  #plt.bar(range(10), predictions[i]) creates a bar plot of the predicted probabilities for each digit.\n",
        "    plt.bar(range(10), predictions[i])\n",
        "  #plt.xlabel(f\"Predicted: {predictions[i].argmax()}\") labels the subplot with the predicted label.\n",
        "    plt.xlabel(f\"Predicted: {predictions[i].argmax()}\")\n",
        "  #plt.show() displays the plot.\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nrwXZoAwUWgJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}